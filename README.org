* Rosenbrock-W algorithm with better Jacobian reuse mechanism and sparse Jacobian support
** Abstract
Implicit solvers in OrdinaryDiffEq.jl are facing performance issues on some large ODEs due to evaluating and decomposing Jacobian matrix too frequently. My GSOC project aims to address such issues in two ways: One is to develop the Rosenbrock-W(ROSW) method which is tolerant of the Jacobian accuracy and to improve the Jacobian reuse  mechanism making it less conservative for large ODEs; Another way is to exploit the sparsity inside many large scale ODEs by evaluating 'orthogonal' columns in the sparse Jacobian matrix simultaneously and emitting Jacobian matrix in sparse form.
** Introduction
Implicit solvers in OrdinaryDiffEq.jl usually spend large proportions of time in solving linear systems when solving large ODEs. The amount of Jacobian evaluations associated with solving linear systems in those solvers often far exceeds the CVODE_BDF solver when solving a specific large ODE system, which implies the possibility to improve the performance by better reusing the Jacobian matrix.

Luckily, the ROSW method have the potential to reduce the number of Jacobian evaluations. It has a higher tolerance for the accuracy of Jacobian matrix while keeping a comparable order as other Rosenbrock methods. Therefore, it doesn't have to evaluate the Jacobian matrix frequently in order to keep it accurate. ODEs whose Jacobian is too hard to evaluate (REF) also benefit from this as they can provide a portion of the matrix (filling the rest with zeros). 

Further performance improvements can be achieved through exploiting the sparsity of the Jacobian matrix that many large ODE problems share. Differentiation tools used by OrdinaryDiffEq.jl simply loop over all the inputs and collect response vectors one by one to form the Jacobian matrix. Assuming the sparse pattern stay unchanged, one can evaluate the derivative of multiple inputs at the same time as long as the respective columns do not share any nonzero rows, which accelerates the evaluation of Jacobian matrix. It is also valuable to produce the sparse form of the Jacobian matrix (if it has some degree of sparsity) so as to utilise the power of sparse linear solvers like GMRES, PCG or KLU.
** Objectives
*** Goal 1: Better Tooling for Rosenbrock & SDIRK methods
Currently, adding a new Rosenbrock or SDIRK method require manually writing the stepping process which have common structure with existing methods. A better approach would be to write a general Rosenbrock/SDIRK stepping routine that directly take the tableau to produce the intended stepping as it would make adding new algorithms (especially for Rosenbrock-W method) a lot more easier while enjoying the benefits from optimization and refactoring of the general method. I will also improve the interpolation methods for Rosenbrock & SDIRK methods as some of them have special higher order (>3) interpolations suggested by the papers. Additionally, I will update documents on adding new Rosenbrock/SDIRK schemes the general method.
**** Implementation Details
There is a general Rosenbrock method (general_rosenbrock_perform_step.jl) available in the code base, but it is outdated and needs to be adapted to the new version. It also lacks optimizations like caching for in-place rhs function and static expansion of loops over the tableau to reduce the overhead. I can start off by writing the in-place version of the perform_step method referencing other Rosenbrock methods, then adjust the code for SDIRK methods. Adding special interpolation methods is straightforward: simply adding new dispatches of _ode_interpolant for the intended methods.
*** Goal 2: Adaptive Rosenbrock-W algorithm
Thanks to the previous work on the general Rosenbrock method, I only need to add the tableau of adaptive ROSW method. There are 3 places that have adaptive ROSW tableaus:
1. Rang and Angermann's paper on 3rd order ROSW for partial DAE
2. Novikov, Shitov and Shokin's paper of (m,k)-ROSW methods
3. Petsc's ROSW code which is (partially) based on Rang and Angermann's paper

I will implement all of the available tableaus listed above and compare their performances. In order to test their correctness and order of accuracy, I will add more test scenarios like non-autonomous ODEs and multivariate ODEs which is more representative than the current test of univariate autonomous ODE.
*** Goal 3: Sparse Jacobian Handling
I will improve the computing process of Jacobian to make use of the sparsity of the Jacobian matrix. Assuming the sparsity pattern is unchanged through solving the ODE system, if there exists a set of columns in the sparse Jacobian matrix that have totally different nonzero rows, that set of columns can be evaluated at the same time. Such sets can be found using matrix colouring algorithm described in Hossain & Steihaug's paper "Optimal Direct determination of sparse Jacobian matrices". There are also two implementations of matrix colouring algorithm for sparse Jacobians: mauro3's MatrixColorings.jl package (https://github.com/mauro3/MatrixColorings.jl) and Petsc's matrix colouring code (https://www.mcs.anl.gov/petsc/petsc-current/src/mat/color/interface/matcoloring.c.html). 
**** Implementation Details
The sparsity pattern can be either supplied by the user in the form of sparse matrix or by evaluating the Jacobian matrix at the initial point and chopping off those sufficiently small values as zeros. Once having the sparse matrix, a column intersection graph can be built where columns are vertices and two vertices are connected when respective columns share at least one nonzero row. Then the colouring algorithm can be applied to the graph to find out a colouring scheme that every edges have vertices of different colours and the set of columns with the same colour is the intended set. While simply assigning vertices with different colours certainly makes a solution, finding out the optimal scheme that minimizes the number of colours is a NP-Complete problem. So instead of finding the optimal solution, A heuristic algorithm is used to find a "good enough" result.

Then, I will modify the differentiation process to differentiate variables with the same colour simultaneously. Normally, the differentiation process of Jacobian matrix loops over all the variables and perturbs/seeds one variable at a time. The collected perturbed/dual number columns stack in order to form the Jacobian matrix. When multiple variables are excited simultaneously, the result column can be seen as the sum of result columns excited separately. Since those columns don't share nonzero rows, they can be retrieved from the sum according to the sparsity pattern. As looping through the sets produced by colouring algorithm, we stack all the retrieved columns to form the Jacobian matrix. An option will be added on whether to produce the Jacobian matrix in sparse form.
*** Goal 4: Jacobian reuse
Jacobian reuse is critical for the performance of ROSW method and other implicit methods. The current reuse method in OrdinaryDiffEq.jl is rather conservative especially for large ODEs compared to some established ODE solvers like CVODE. Kennedy and Carpenter's review on DIRK also mentioned some advanced Jacobian reuse method. However, both CVODE and the paper only have reuse algorithm for implicit with Newton's method where both number of iteration steps and local error can be used to determine whether to reuse the Jacobian matrix, while in Rosenbrock method we only have one factor-local error. As a result, I believe it is better to start from implementing reuse method of implicit solvers with Newton's method according to CVODE's code and Kennedy&Carpenter's paper. Then, I will try to improve the reuse method for Rosenbrock solvers based on experiments and previous experiences.
** Potential Difficulties
It is difficult to write a decent Jacobian reuse algorithm since the Jacobian matrix is problem-specific. Small ODEs might benefit from frequent Jacobian update to gain high accuracy, while large ODEs usually prefer as little Jacobian evaluations as possible due to their high cost. Heuristics are needed to determine which reuse scheme is applied according to the problem, but such heuristics require lots of experiments. So, I allocate a long period of time in tackling it and assign it as the last goal to ensure that I would at least finish previous goals before I'm stuck by this problem.
** Potential Mentors
Yingbo Ma would be my primary mentor, and Christopher Rackauckas would be my secondary mentor.
Milestones
** Summer Logistics
I can work 40 hours per week from mid of May to September, but I'll have about 2-3 weeks for holiday in June and July. In general, I can devote at least 400 hours in this project.
** Code Portfolio
I have contributed a PR on adding a new Rosenbrock-W solver to OrdinaryDiffEq.jl:
- add Rosenbrock-W method 6S4O(S) (https://github.com/JuliaDiffEq/OrdinaryDiffEq.jl/pull/701)
** Deliverables
- General Rosenbrock/SDIRK solver
- Adaptive Rosenbrock-W solvers
- New option for sparse matrix
- Lower Jacobian evaluations
** About Me
I am a final year undergraduate majored in Atmospheric Science at the University of Manchester. I'm probably going to the MSc program of Computing Science and Engineering at ETHz. I have been using Julia extensively since last year to develop an atmospheric chemistry box model JlBox as my final year project. The model invokes DifferentialEquations.jl for solving ODEs with thousands of variables, so the performance of the ODE solver is a great concern to me.
** Academic Details
- University: the University of Manchester
- Major: Atmospheric Science (final year)
- GPA: 3.85/4.0
** Contact Information
- Email: huanglangwen@outlook.com
- Github: huanglangwen
